{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdaf0e07-3ca6-4a76-941f-bbba35585286",
   "metadata": {},
   "source": [
    "# Redaction and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bdb58b-5bf8-4f8e-887e-34e3edc0f0a2",
   "metadata": {},
   "source": [
    "## calculating predictions for each redaction -variation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c88f3-e359-4793-9868-099e84899340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_predictions_for_each_redaction(model_in_use,segmentwise_attributions,image,im,topk,top10list,prediction_id,list_of_masks,new_segs,predictions):    \n",
    "    top_heatmaps=100\n",
    "    masking_type='normal/'\n",
    "    dict1={}\n",
    "    dict2={}\n",
    "    dict_for_redacted_images=[]\n",
    "    all_predictions_after_this_redaction=[]\n",
    "    for i in top10list:\n",
    "        dict1[i]=[]\n",
    "        dict2[i]=[]\n",
    "        dict1[i].append(predictions[0][i].numpy())\n",
    "        # dict2[i].append(100.0)\n",
    "    numbered_masks = {ind: mask for ind, mask in enumerate(new_segs)}\n",
    "    oldmask=np.zeros(numbered_masks[0].shape, dtype=bool)\n",
    "    all_predictions_after_this_redaction.append([])\n",
    "    # for i in top10list:\n",
    "    #         dict1[i].append(predictions1[0][i].numpy())\n",
    "    \n",
    "\n",
    "    # while top_heatmaps>=0:\n",
    "    #     # for top_heatmaps in range(100,-0.9,-0.1)\n",
    "    #     mask = segmentwise_attributions[prediction_id] > np.percentile(segmentwise_attributions[prediction_id], top_heatmaps)\n",
    "    #     new_im=mask_on_image(im , mask, masking_type)\n",
    "    #     new_im1=mask_on_image(image , mask, masking_type)\n",
    "    #     (predictions1,decoded_predictions1,top10list1,top1000list1,id_to_name1)=predict_img(model_in_use,new_im,print_data=False)\n",
    "    #     dict_for_redacted_images.append(new_im1)\n",
    "    #     for i in top10list:\n",
    "    #         dict1[i].append(predictions1[0][i].numpy())\n",
    "    #     top_heatmaps=top_heatmaps-1\n",
    "\n",
    "    for mask_id in list_of_masks[prediction_id]:\n",
    "        # for top_heatmaps in range(100,-0.9,-0.1)\n",
    "        mask=numbered_masks[mask_id]\n",
    "        mask=np.logical_or(mask,oldmask)\n",
    "        new_im=mask_on_image(im , mask, masking_type)\n",
    "        new_im1=mask_on_image(image , mask, masking_type)\n",
    "        oldmask=mask\n",
    "        # plt.imshow(mask)\n",
    "        # plt.show()\n",
    "        \n",
    "        (predictions1,decoded_predictions1,top10list1,top1000list1,id_to_name1)=predict_img(model_in_use,new_im,print_data=False)\n",
    "        dict_for_redacted_images.append(new_im1)\n",
    "        all_predictions_after_this_redaction.append(predictions1[0].numpy())\n",
    "        for i in top10list:\n",
    "            dict1[i].append(predictions1[0][i].numpy())\n",
    "\n",
    "    # plt.imshow(mask)\n",
    "    # plt.show()\n",
    "    \n",
    "    for key in dict1:\n",
    "        for k in range(len(dict1[key])):                \n",
    "            dict2[key].append((dict1[key][k]/dict1[key][0])*100)\n",
    "    return [dict1,dict2,dict_for_redacted_images,all_predictions_after_this_redaction]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329405ad-6539-456c-ac69-93ca99a2494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_predictions_by_redactions(model_in_use,segmentwise_attributions,image,im,topk,top10list,pth,list_of_masks,new_segs,predictions,redo=False,dont_save=False):\n",
    "\n",
    "    if os.path.exists(pth+'_redactions'+'.pkl') and redo==False:\n",
    "        with open(pth+'_redactions'+'.pkl', 'rb') as file:\n",
    "            x=pickle.load(file)\n",
    "            # [final_prediction_dictionary,final_prediction_dictionary_with_percentages,final_redacted_images]=pickle.load(file)\n",
    "        print('loaded final predictions after redactions from file for type1 check')\n",
    "        return x\n",
    "        # return final_prediction_dictionary,final_prediction_dictionary_with_percentages,final_redacted_images,all_predictions_after_redaction\n",
    "\n",
    "    else:\n",
    "        all_predictions_after_redaction={}\n",
    "        final_prediction_dictionary={}\n",
    "        final_prediction_dictionary_with_percentages={}\n",
    "        final_redacted_images={}\n",
    "        for prediction_id in top10list[:topk]:\n",
    "            print('loading predictions while redating '+str(prediction_id))\n",
    "            prediction_dictionary,prediction_dictionary_with_percentages,dict_for_redacted_images,all_predictions_after_this_redaction=calculate_predictions_for_each_redaction(model_in_use,segmentwise_attributions,image,im,topk,top10list,prediction_id,list_of_masks,new_segs,predictions)\n",
    "            final_prediction_dictionary[prediction_id]=prediction_dictionary\n",
    "            final_prediction_dictionary_with_percentages[prediction_id]=prediction_dictionary_with_percentages\n",
    "            all_predictions_after_redaction[prediction_id]=all_predictions_after_this_redaction\n",
    "            # final_redacted_images[prediction_id]=dict_for_redacted_images # undo this if you are not using function to calcluate redaction images\n",
    "\n",
    "        if dont_save== False:\n",
    "            with open(pth+'_redactions'+'.pkl', 'wb') as file:\n",
    "                pickle.dump([final_prediction_dictionary,final_prediction_dictionary_with_percentages,final_redacted_images,all_predictions_after_redaction], file)\n",
    "                file.close()\n",
    "\n",
    "        return [final_prediction_dictionary,final_prediction_dictionary_with_percentages,final_redacted_images,all_predictions_after_redaction]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb63ee8-fbc9-4597-abf3-c64b76cee429",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a39e81-54ea-4edf-80ba-592b2ee95d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_for_type1_redaction1(redacted_image_with_pred1,redacted_mask_with_pred1,final_prediction_dictionary,first_redaction,id_to_name,prediction1,prediction2,redaction1_percentile,type_of_graph):\n",
    "    ROWS=1\n",
    "    COLS=2\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-5)))\n",
    "    axs.flat[0].imshow(redacted_image_with_pred1)\n",
    "    axs.flat[1].imshow(redacted_mask_with_pred1)\n",
    "    \n",
    "    axs.flat[0].axis('off')\n",
    "    axs.flat[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    ROWS=1\n",
    "    COLS=2\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-8)))\n",
    "    # for xy in list(final_prediction_dictionary[prediction1].keys())[:5]:\n",
    "    #     axs.flat[0].plot(range(len(final_prediction_dictionary[prediction1][xy])),final_prediction_dictionary[prediction1][xy],label=id_to_name[xy])\n",
    "    axs.flat[0].plot(range(len(final_prediction_dictionary[prediction1][prediction1])),final_prediction_dictionary[prediction1][prediction1],label=id_to_name[prediction1])\n",
    "    axs.flat[0].plot(range(len(final_prediction_dictionary[prediction1][prediction2])),final_prediction_dictionary[prediction1][prediction2],label=id_to_name[prediction2])\n",
    "    axs.flat[0].legend()\n",
    "    if type_of_graph == 'prob':\n",
    "        # axs.flat[0].set_title('probabilities vs redactions')\n",
    "        axs.flat[0].set_ylabel('probabilities',fontsize=('12'))\n",
    "        axs.flat[0].set_xlabel('redactions',fontsize=('12'))\n",
    "    elif type_of_graph == 'pre_sm':\n",
    "        axs.flat[0].set_title('pre_softmax vs redactions')\n",
    "        axs.flat[0].set_ylabel('pre_softmax')\n",
    "        axs.flat[0].set_xlabel('redactions')\n",
    "    axs.flat[0].axvline(x=redaction1_percentile, color='r', linestyle=':',label=str(redaction1_percentile))\n",
    "    # for xy in list(first_redaction.keys())[:5]:\n",
    "    #     axs.flat[1].plot(range(len(first_redaction[xy])),first_redaction[xy],label=id_to_name[xy])\n",
    "    axs.flat[1].plot(range(len(first_redaction[prediction1])),first_redaction[prediction1],label=id_to_name[prediction1])\n",
    "    axs.flat[1].plot(range(len(first_redaction[prediction2])),first_redaction[prediction2],label=id_to_name[prediction2])\n",
    "    axs.flat[1].legend()\n",
    "    # axs.flat[1].set_title('percentages vs redactions')\n",
    "    axs.flat[1].set_ylabel('Percentages',fontsize=('12'))\n",
    "    axs.flat[1].set_xlabel('Number of redactions',fontsize=('12'))\n",
    "    axs.flat[1].axvline(x=redaction1_percentile, color='r', linestyle=':',label=str(redaction1_percentile))\n",
    "    plt.savefig('spider5/type2_graph1_fig.svg',format='svg')\n",
    "    plt.show()\n",
    "\n",
    "def plot_for_type1_redaction2(redacted_image_with_pred2,redacted_mask_with_pred2,final_prediction_dictionary,second_redaction,id_to_name,prediction1,prediction2,redaction2_percentile):\n",
    "\n",
    "\n",
    "    ROWS=1\n",
    "    COLS=2\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-5)))\n",
    "    axs.flat[0].imshow(redacted_image_with_pred2)\n",
    "    axs.flat[1].imshow(redacted_mask_with_pred2)\n",
    "    axs.flat[0].axis('off')\n",
    "    axs.flat[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ROWS=1\n",
    "    COLS=2\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-8)))\n",
    "    # for xy in list(final_prediction_dictionary[prediction2].keys())[:5]:\n",
    "    #     axs.flat[0].plot(range(len(final_prediction_dictionary[prediction2][xy])),final_prediction_dictionary[prediction2][xy],label=id_to_name[xy])\n",
    "\n",
    "    axs.flat[0].plot(range(len(final_prediction_dictionary[prediction2][prediction1])),final_prediction_dictionary[prediction2][prediction1],label=id_to_name[prediction1])\n",
    "    axs.flat[0].plot(range(len(final_prediction_dictionary[prediction2][prediction2])),final_prediction_dictionary[prediction2][prediction2],label=id_to_name[prediction2])\n",
    "    axs.flat[0].legend()\n",
    "    axs.flat[0].set_title('probabilities vs redaction percentile')\n",
    "    axs.flat[0].set_ylabel('probabilities')\n",
    "    axs.flat[0].set_xlabel('redaction percentile')\n",
    "    axs.flat[0].axvline(x=redaction2_percentile, color='r', linestyle=':',label=str(redaction2_percentile))\n",
    "    # for xy in list(second_redaction.keys())[:5]:\n",
    "    #     axs.flat[1].plot(range(len(second_redaction[xy])),second_redaction[xy],label=id_to_name[xy])\n",
    "\n",
    "    axs.flat[1].plot(range(len(second_redaction[prediction1])),second_redaction[prediction1],label=id_to_name[prediction1])\n",
    "    axs.flat[1].plot(range(len(second_redaction[prediction2])),second_redaction[prediction2],label=id_to_name[prediction2])\n",
    "    axs.flat[1].legend()\n",
    "    # axs.flat[1].set_title('percentages vs redaction percentile')\n",
    "    axs.flat[1].set_ylabel('Percentages',fontsize=('12'))\n",
    "    axs.flat[1].set_xlabel('Number of redactions',fontsize=('12'))\n",
    "    axs.flat[1].axvline(x=redaction2_percentile, color='r', linestyle=':',label=str(redaction2_percentile))\n",
    "    plt.savefig('spider5/type2_graph2_fig.svg',format='svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_for_type2_sequence_of_masks(segmentwise_attributions,prediction1,prediction2,redaction1_percentile,redaction2_percentile):\n",
    "    xy=segmentwise_attributions[prediction1] > np.percentile(segmentwise_attributions[prediction1], 100)\n",
    "    mask_temp=np.zeros(xy.shape)\n",
    "    mask_temp_array=[]\n",
    "    mask_temp_array2=[]\n",
    "    for o in range(redaction1_percentile+1):\n",
    "        mask_temp_new = segmentwise_attributions[prediction1] > np.percentile(segmentwise_attributions[prediction1], 100-o)\n",
    "        if np.all(mask_temp_new== mask_temp):\n",
    "            continue\n",
    "        else:\n",
    "            mask_temp= mask_temp_new\n",
    "            mask_temp_array.append(mask_temp_new)\n",
    "            mask_temp_array2.append(o)\n",
    "   \n",
    "    n=len(mask_temp_array)                \n",
    "    # n=redaction1_percentile+1\n",
    "    ROWS = math.floor(math.sqrt(n))\n",
    "    COLS = math.ceil(n / ROWS)\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-5)))\n",
    "    for o in range(len(mask_temp_array)):\n",
    "        axs.flat[o].imshow(mask_temp_array[o])\n",
    "        axs.flat[o].set_title(mask_temp_array2[o])\n",
    "    # for o in range(redaction1_percentile+1):\n",
    "    #     mask_temp = segmentwise_attributions[prediction1] > np.percentile(segmentwise_attributions[prediction1], 100-o)\n",
    "    #     axs.flat[o].imshow(mask_temp)\n",
    "    plt.show()\n",
    "    \n",
    "    xy=segmentwise_attributions[prediction1] > np.percentile(segmentwise_attributions[prediction1], 100)\n",
    "    mask_temp=np.zeros(xy.shape)\n",
    "    mask_temp_array=[]\n",
    "    mask_temp_array2=[]\n",
    "    for o in range(redaction2_percentile+1):\n",
    "        mask_temp_new = segmentwise_attributions[prediction2] > np.percentile(segmentwise_attributions[prediction2], 100-o)\n",
    "        if np.all(mask_temp_new== mask_temp):\n",
    "            continue\n",
    "        else:\n",
    "            mask_temp= mask_temp_new\n",
    "            mask_temp_array.append(mask_temp_new)\n",
    "            mask_temp_array2.append(o)\n",
    "    \n",
    "    \n",
    "    n=len(mask_temp_array)                \n",
    "    # n=redaction1_percentile+1\n",
    "    ROWS = math.floor(math.sqrt(n))\n",
    "    COLS = math.ceil(n / ROWS)\n",
    "    UPSCALE_FACTOR = 10\n",
    "    fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * UPSCALE_FACTOR, COLS * (UPSCALE_FACTOR-5)))\n",
    "    for o in range(len(mask_temp_array)):\n",
    "        axs.flat[o].imshow(mask_temp_array[o])\n",
    "        axs.flat[o].set_title(mask_temp_array2[o])\n",
    "    # for o in range(redaction1_percentile+1):\n",
    "    #     mask_temp = segmentwise_attributions[prediction1] > np.percentile(segmentwise_attributions[prediction1], 100-o)\n",
    "    #     axs.flat[o].imshow(mask_temp)\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93996e9a-711f-4ad4-ad26-7795a13abc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025b65a-6044-4c81-8c2f-83305ecb0ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98945245-d6dd-413d-8023-7c4b2e8c4052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4c8d8-5ee2-4581-84d1-b8fa0ac7c923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
